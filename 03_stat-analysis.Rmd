---
title: "03_stat-analysis"
author: Irene Romero Rodríguez
  output:
  github_document:
    toc: TRUE
    toc_depth: 2
---

# Introduction: Packages

Nous allons continuer ici, à partir des données traitées avec dada2, l'analyse de nos échantillons. Pour ce faire nous allons travailler avec le package phyloseq ainsi que des packages permettant de tracer diverses figures graphiques. 

```{r}
library(rmarkdown)
library(knitr)
library(phyloseq); packageVersion("phyloseq")
library(Biostrings); packageVersion("Biostrings")
library(ggplot2); packageVersion("ggplot2")
library(dada2)
library(DECIPHER)
library(phangorn)
```

rmarkdown est un package qui permet la création de documents dynamiques. Grâce à ce package on peut créer des outputs qui peuvent être plus ésthétiques. knitr est un package ayant plusieurs utilités cependant ici on va l'utiliser avec la fonction knit avec le propos de créer un document github à la fin. Quand on utilise cette fonction ce que l'on est entraîn de faire est de prendre toutes les données entrées dans le document; extraction du code en R suivant une liste de modèles et rédigeant le résultat dans un document de sortie (output). Biostring est un package permettant le traitement de données biologiques écrites en chaîne de caractères. Cet outil va répertorier des grandes quantités de chaînes de caractères, comme par exemple des séquences de nucléotides et peut les comparer entre elles (un exemple de une des fonctions contenues dans le package de Biostring). ggplot2 est un package contenant des outils pour la création de graphiques suivant les consignes de l'utilisateur: quel graphique est quoi; étiquettes; couleurs... DECIPHER est un autre package de bioconductor (comme Biostring) qui permet de curer, analyser et manipuler des séquences biologiques (comme par exemple aligner des séquences). Finalement phangorn est un package contenant des outils et méthodes permettant la formation d'arbres phylogénetiques (comme Maximum likelihood ou Maximum Parsimony). 

*Fun fact*: Lors de la première séance de TP je me disais bien que "phangorn" me disait quelque chose. C'est une excellente référence (probablement...en tout cas je l'espère sinon je serai déçue) au Seigneur des Anneaux. En effet la fôret de Treebeard (apparament Sylvebarbe en français, Barbol en espagnol) est aussi nommée la fôret de *F*angorn (avec F mais même prononciation). Ce qui est encore plus drôle c'est que dans cette fôret on retrouve des êtres millenaires et anciens, donc la ressemblence avec faire un arbre phylogénétique, qui permet de retrouver les liens de parenté en fonction de l'évolution me paraît tout simplement géniale. 10/10 à la personne qui a eu l'idée (j'espère qu'en faisant exprès sinon s'il vous plaît ne me jugez pas, j'aime beaucoup l'ouvrage, c'est tout). 

# Objet phyloseq

Sur cette étape on va créer une data.frame qui est un tableau dans lequel vont être repertoriées des informations des échantillons. Pour ce faire on commence par créer un environnement de travail adéquat.

```{r}
samples.out <- rownames(seqtab.nochim)
subject <- sapply(strsplit(samples.out, "D"), `[`, 1)
gender <- substr(subject,1,1)
subject <- substr(subject,2,999)
day <- as.integer(sapply(strsplit(samples.out, "D"), `[`, 2))
samdf <- data.frame(Subject=subject, Gender=gender, Day=day)
samdf$When <- "Early"
samdf$When[samdf$Day>100] <- "Late"
rownames(samdf) <- samples.out
```

 On extrait l'information des rangées de la table où on a stocké nos informations une fois que les chimères ont été éliminées. Ensuite on change le nom de ces informations (échantillons) et on ajoute un D. Ces nouveaux noms sont stockés sur l'objet subject. Ensuite on extrait certaines des informations concernant ces subjects et on les assigne à des objets nommés respectivement en fonction de l'information qu'ils contiennent comme gender. On extrait aussi le jour. Ensuite on crée la data frame qui va avoir en rangées les informations concernant aux samples. En colonnes on va avoir le sujet; le genre; le jour et une colonne pour spécifier si c'est un prélévement effectué tôt ou tard en fonction des jours. 

Ensuite on fait la construction d'un objet phyloseq à partir des résultats de dada2: 

```{r}
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxa))
ps <- prune_samples(sample_names(ps) != "Mock", ps) # Remove mock sample
```

Cet objet phyloseq va contenir une table d'observation avec les OTU; les informations extraites grâce à la data.frame et une table taxonomique. De plus, on élimine la communauté mock.

On procede maintenant à attribuer des string chains plus courtes aux noms des dossiers afin d'avoir plus de facilité pour travailler sur des tableaux par exemple. On veut cependant garder la séquence en entier, pour cela on va garder la séquence sur le refseq slot de l'objet et renommer le taxa pour un nom plus court:

```{r}
dna <- Biostrings::DNAStringSet(taxa_names(ps))
names(dna) <- taxa_names(ps)
ps <- merge_phyloseq(ps, dna)
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))
ps
```

On voit ci-dessus l'objet ps et on a donc un bilan des tables formées avec cet objet comme la table d'observation.

# L'alpha diversité

On utilise maintenant cet objet pour travailler avec phyloseq et faire des études sur les données: 
On commence par l'alpha-diversité en traçant les graphiques d'alpha diversité en fonction de l'indice de Shannon dans un premier temps, et de Simpson deuxièmement. On distingue les deux temps de l'échantillonnage qui sont regroupés par un changement de couleur. 

```{r}
plot_richness(ps, x="Day", measures=c("Shannon", "Simpson"), color="When")
```

La fonction plot richness permet d'estimer la richesse au sein des échantillons et remets ces infos vers une figure ggplot2 (graphique). Cette estimation est effectuée donc premièrement par des mesures en applicant l'indice de Shannon puis de Simpson comme indiqué sur l'assignation de measures. De plus on choisi de mettre des couleurs qui vont être différents en fonction de la variable "When". Ces données tel quelles ne nous montrent pas vraiment de différence de richesse en fonction du temps de l'échantillonnage. Il faut passer par une ordination.

## Ordination.

On continue donc en effectuant une ordination pour l'étude par groupes:

```{r}
# Transform data to proportions as appropriate for Bray-Curtis distances
ps.prop <- transform_sample_counts(ps, function(otu) otu/sum(otu))
ord.nmds.bray <- ordinate(ps.prop, method="NMDS", distance="bray")
```

La première étape de ce code permet de transformer les valeurs trouvées dans l'OTU (et grâce à celle ci) en abondances relatives. Ensuite on crée une ordination avec ces mesures. La fonction ordinate permet de créer cette ordination. Le choix d'ordination est ici NMDS (Non metric multidimensinal scaling) qui est une méthode basée dans les rangs afin de représenter la dissimilarité. On utilise la distance de Bray-Curtis afin de mesurer la dissimilarité entre échantillons.

Et on trace le graphique de l'ordination:

```{r}
plot_ordination(ps.prop, ord.nmds.bray, color="When", title="Bray NMDS")
```

Grâce à cette ordination on observe en effet deux groupes bien distincts détérminés par un échantillonnage fait tôt ou tard. 

## Graphique de barres (abondance relative).

On finalise cette partie de l'étude en effectuant un graphique de barres pour observer l'abondance relative des espèces en fonction de leur groupe (Early ou late). On choisi les 20 plus abondantes:

```{r}
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x="Day", fill="Family") + facet_wrap(~When, scales="free_x")
```

On n'observe pas vraiment de différence sgnificative pouvant expliquer la distinction en groupes.On peut à la limite dire qu'il y a légèrement plus de Bacteriodaceae; Rikenellaceae et des NA dans les échantillons du groupe early. Mais encore une fois les différences ne sont pas très grandes comme pour pouvoir dire de façon sûre que ce soit à cause de ça.

# Ajout d'échantillons

Pour le reste du tutoriel phyloseq nous avons téléchargé des données basées sur la même étude que depuis le début, mais ayant plus d'échantillons. Ces données ont déjà été traitées.

```{r}
ps_connect <-url("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/ps.rds")
ps = readRDS(ps_connect)
ps
```

# Filtrage

Dans cette partie nous allons filtrer nos données de travail. Cependant, contrairement au filtrage fait sur la partie de DADA2 ici nous allons filtrer grâce, d'une part de la taxonomie, et d'autre part en fonction de la prévalence des taxons dans les échantillons. 

## Filtage taxonomique

Afin de pouvoir faire un filtrage et ne pas tenir en compte les espèces moins abondantes qui peuvent être issues d'erreurs de séquençage on commence par analyser les rangs puis ensuite on choisi un niveau auquel on veut étudier pour filtrer nos échantillons.

### Show available ranks in the dataset
```{r}
rank_names(ps)
```

Ici on voit que l'on a des données allant depuis Kingdom (Domaine) jusqu'au genus. Nous allons évaluer l'abondance présente dans chaque phylum; pour cela on reprend la table de données taxonomiques crée avec phyloseq et stockée dans l'objet phyloseq ps. 

```{r}
# Create table, number of features for each phyla
table(tax_table(ps)[, "Phylum"], exclude = NULL)
```

On observe grâce à cette table qu'il y a plusieurs phylums dans lesquels on n'observe qu'une seul élément caractéristique à ces phylums dans les échantillons. Du fait de leur faible abondance ces phylums seraient intéressants à filtrer. Cependant ici on se centre plutôt sur les 6 NA. En fait on s'est placé au niveau du Phylum parceque justement c'est un ordre supérieur de classification. On sait que l'on travaille ici avec des bactéries, donc étudier au niveau du domaine n'est pas intéressant. Cependant au niveau du Phylum on observe quand même que l'on a des séquences auxquelles on ne peut pas attribuer une taxonomie. A moins d'être entraîn de travailler dans un projet innovateur de séquençage voulant trouver des souches bactériennes nouvelles (et encore il faudrait se méfier), et ici ce n'est pas le cas, ces séquences sont probablement issues d'artifacts. 

On va donc enlever les "NA" d'entre nos séquences:

```{r}
ps <- subset_taxa(ps, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))
```

Maintenant on va faire un étude de prévalence pour ensuite filtrer ces mêmes données de prévalence:


```{r}
# Compute prevalence of each feature, store as data.frame
prevdf = apply(X = otu_table(ps),
               MARGIN = ifelse(taxa_are_rows(ps), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf = data.frame(Prevalence = prevdf,
                    TotalAbundance = taxa_sums(ps),
                    tax_table(ps))
```


Grâce à la fonction apply nous allons créer un objet prevdf dans lequel nous allons extraire le nombre de fois qu’un phylum apparait sur un échantillon en prennant en compte qu’il doit apparaitre au moins une fois (x>0). Ensuite on crée une table de données (data frame) contenant la prévalence définie sur prevdf avant, ainsi que l’abondance totale (somme des taxa de l’objet ps) et la table taxonomique de ps.

```{r}
plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})
```

Grâce à la fonction plyr::ddply nous avons crée une table/matrice.  Grâce à la fonction cbind on donne des instructions à la fonction ddply de calculer les moyenne des prévalences dans les échantillons (qui vont apparaître en une première colonne) et la somme des prévalence dans les échantillons, c'est à dire le nombre de fois total dans lequel on retrouve des séquences appartenant à un tel ou un autre phylum entre tous les échantillons (prévalence totale, qui apparaît dans la deuxième colonne). Avant le cbind on choisi de faire cette matrice sur les données du Phylum de l’objet prevdf.

On observe sur la table sur laquelle on a évaluée les abondances respectives de données en fonction du que en effet il y a dans 13 écahntillons des éléments de actinobacteria, si on divise le nombre total de séquences d’actinobactéria (prévalence totale) par la prévalence moyenne on trouve 13 soit le nombre total d'échantillons dans lesquels ça apparait. 
On observe pour fusobacteria qu’il y a que 2 séquences ayant en plus une fréquence d’apparition de 1% donc c’est probablement deux séquences issues d'erreurs de séquençage. Surtout en comparant au nombre d'apparition d'autres séquences. Quant à Deinococcus; Verrumicrobia et Tenericutes il y a quand même une quantité de prévalence de la sequence plutôt importante. Cependant on va enlever les deinococcus pour l’exemple même si comme ça apparait 52 fois ça commence a être possible que ce soit une bactérie qui apparait en très petite quantité car elle est pas abondante dans le milieu de prélevement. 

Nous avons donc vu et décidé qu'il faut enlever les séquences correspondants aux phylum Fusobacteria et Deinococcus-Thermus. On crée un nouveau objet filterPhyla dans lequel on garde ces séquences, puis grâce à la fonction subset_taxa on enlève de ps ces données, et on stocke le résultat dans un nouveau objet phyloseq:ps1.

```{r}
# Define phyla to filter
filterPhyla = c("Fusobacteria", "Deinococcus-Thermus")
# Filter entries with unidentified Phylum.
ps1 = subset_taxa(ps, !Phylum %in% filterPhyla)
ps1
```

## Filtration de prévalence.

Nous avons maintenant des données de prévalence en fonction du Phylum. Cependant on peut encore filtrer ces données. On commence par sélectioner les données de prévalence de l'objet ps1 en se centrant que sur le Phylum. Ensuite on trace des graphiques: graphique par Phylum sur lesquels on donne des paramètres aesthetiques dans lesquelles on veut dans l'axe x l'abondance totale; en axe y la prévalence au sein du phylum des échantillons de ps et on veut une couleur par phylum. On choisit de même de rajouter une ligne à 0,05 soit 5% de prévalence dans les divers phylums, cette ligne est une ligne de type 2 (non continue) et d'opacité (alpha) 0,5 afin qu'elle ne perturbe pas trop la lecture du graphique. On définit les paramètres concernant les points du graphique (épaisseur du point avez size et l'alpha), puis on précise que l'on trace un graphique en échelle logarithmique 10. De plus on ajoute des titres d'axe mais on enlève les légendes des graphiques (vu que l'on veut un graphique par Phylum).

```{r}
# Subset to the remaining phyla
prevdf1 = subset(prevdf, Phylum %in% get_taxa_unique(ps1, "Phylum"))
ggplot(prevdf1, aes(TotalAbundance, Prevalence / nsamples(ps),color=Phylum)) +
  # Include a guess for parameter
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) +  geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none")
```

On observe que en effet il y a aux alentours de 17-18 points au total entre les divers graphiques qui sont sous le seuil de 5% de prévalence. Nous allons donc choisir de les enlever afin de d'utiliser des données que l'on considère vont Être suffissament fiables. Ce filtrage que l'on est entrain d'effectuer est un filtrage "sans supervision". En effet, depuis le début du tutoriel on travaille avec des séquences que l'on filtre à base de comparaisons à des bases de données; entre elles etc. Mais la on choisi quoi filtrer par rapport à ce qui nous conviens et d'après ce que l'on voit (même si on a filré le score de qualité en faisant un choix, on a basé le choix sur un calcul et des comparaisons faites entre les séquences elles mêmes par rapport à leur technique de séquençage). 

On définit donc la prévalence comme valable à partir du seuil de 5% de présence:

```{r}
# Define prevalence threshold as 5% of total samples
prevalenceThreshold = 0.05 * nsamples(ps)
prevalenceThreshold
```

Ensuite on crée un nouveau objet phyloseq, ps2, dans lequel on stocke toutes les séquences que l'on garde, c'est à dire, les séquences au-dessus du seuil de prévalence (keepTaxa). 

```{r}
# Execute prevalence filter, using `prune_taxa()` function
keepTaxa = rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
ps2 = prune_taxa(keepTaxa, ps)
```


# Arbre phylogénétique ou regroupement des taxons.

Même si il serait plus pratique de créer une agroupation des bactéries par leur fonction, dû à la simplicité, nous allons faire un arbre phylogénétique basé sur la similarité de taxonomie des bactéries des échantillons. Pour ce faire nous devons donner des instructions afin de créer un arbre classant les bactéries en fonction de leur appartenence à un même genre:

```{r}
# How many genera would be present after filtering?
length(get_taxa_unique(ps2, taxonomic.rank = "Genus"))
```

Cette dernière commande nous a servi à évaluer la quantité de genres bactériens différents présents dans nos échantillons après tous les tris que l'on a effectué. On en a 49. 
On crée un objet phyloseq ps3 dans lequel on va "merge" soit fusionner nos résultats jusqu'à un certain niveau taxonomique; ici en l'ocurrence jusqu'au genre bactérien. Ainsi la fonction tax_glom permet de faire cette fusion pour créer les noeuds de notre arbre.

```{r}
ps3 = tax_glom(ps2, "Genus", NArm = TRUE)
```

L'arbre phylogénetique basé sur la taxonomie n'est pas mal, or il se peut que nos séquences ne soient pas suffissament bonnes et l'assignation taxonomique soit compliquée. Ou bien il se peut qu'on ne dispose pas de ces informations taxonomiques. Ainsi on peut faire un arbre sur une méthode similaire au clustering d'OTUs mais il y a une composante évolutionnaire entre les séquences qui est tenue en compte. En effet on va créer un arbre en se basant sur la distance phylogenetique entre les éléments caractéristiques définissant un groupe taxonomique. Pour faire cela on défini tout d'abord un indice de similiarité au au dessous duquel on ne joins pas deux branchest et au dessus du quel on considère que deux séquences sont suffissament proches. Cet indice ici va être nommé h1. Ensuite on crée un objet phyloseq, ps4, qui va contenir l'union d'éléments basée sur la distance (hauteur) h. 

```{r}
h1 = 0.4
ps4 = tip_glom(ps2, h = h1)
```

C'est le moment de tracer notre arbre. Afin de pouvoir comparer nos résultats on va tracer un arbre avec nos données avant d'avoir été traitées pour fusionner en fonction de la taxonomie ou bien en fonction de leur distance; puis un arbre pour la fusion taxonomique et un autre pour la fusion par distance. On décide donner des titres aux arbres pour ne pas les confondre et on indique que la taille de police des titres est 15. Ensuite on crée p2tree avec la fonction plot_tree, cette fonction va tracer l'arbre de l'objet ps2 (données sans traiter) avec la méthode treeonly, cette partie de la fonction indique si l'on veut des annotations sur notre arbre ou pas (points de robustesse). L'option de ladderize permet de reorganiser les noeuds des arbres en fonction de leur profondeur par rapport aux nombre de branches qui partent d'un noeuf et leur profondeur (un noeu où une branche donné issue à un autre noeud puis un autre etc...). Le deuxième arbre est crée à partir de ps3 et donc des données fusionnées par taxonomie et l'arbre trois en fonction de l'hauteur (distance), donc à partir de l'objet ps4.

```{r}
multiPlotTitleTextSize = 15
p2tree = plot_tree(ps2, method = "treeonly",
                   ladderize = "left",
                   title = "Before Agglomeration") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p3tree = plot_tree(ps3, method = "treeonly",
                   ladderize = "left", title = "By Genus") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p4tree = plot_tree(ps4, method = "treeonly",
                   ladderize = "left", title = "By Height") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
```

On utilise ensuite la fonction gridExtra pour tracer les trois arbres sur une même ligne. 

```{r}
library(gridExtra)
# group plots together
grid.arrange(nrow = 1, p2tree, p3tree, p4tree)
```

Avant de fusionner nos données on obtient un arbre qui a beaucoup de branches et qui est pratiquement ilisible. Après fusion de données on constate que l'arbre se basant sur la distance des séquences permet de donner plus de précisions que l'arbre basé sur la taxonomie mais tout en restant plus clair et lisible que celui des données non traitées. 

# Transformation des valeurs d'abondance.



```{r}
plot_abundance = function(physeq,title = "", 
                          Facet = "Order", Color = "Phylum"){
  # Arbitrary subset, based on Phylum, for plotting
  p1f = subset_taxa(physeq, Phylum %in% c("Firmicutes"))
  mphyseq = psmelt(p1f)
  mphyseq <- subset(mphyseq, Abundance > 0)
  ggplot(data = mphyseq, mapping = aes_string(x = "sex",y = "Abundance",
                              color = Color, fill = Color)) +
    geom_violin(fill = NA) +
    geom_point(size = 1, alpha = 0.3,
               position = position_jitter(width = 0.3)) +
    facet_wrap(facets = Facet) + scale_y_log10()+
    theme(legend.position="none")
}
```

```{r}
# Transform to relative abundance. Save as new object.
ps3ra = transform_sample_counts(ps3, function(x){x / sum(x)})
```

```{r}
plotBefore = plot_abundance(ps3,"")
plotAfter = plot_abundance(ps3ra,"")
# Combine each plot into one graphic.
grid.arrange(nrow = 1,  plotBefore, plotAfter)
#sur le code du tutoriel on mets nrow=2 mais ici on change par 1 afin d'avoir quelque chose de plus esthetique et lisible
```
```{r}
psOrd = subset_taxa(ps3ra, Order == "Lactobacillales")
plot_abundance(psOrd, Facet = "Genus", Color = NULL)
```

```{r}
qplot(sample_data(ps)$age, geom = "histogram",binwidth=20) + xlab("age")
```

```{r}
qplot(log10(rowSums(otu_table(ps))),binwidth=0.2) +
  xlab("Logged counts-per-sample")
```

```{r}
sample_data(ps)$age_binned <- cut(sample_data(ps)$age,
                              breaks = c(0, 100, 200, 400))
levels(sample_data(ps)$age_binned) <- list(Young100="(0,100]", Mid100to200="(100,200]", Old200="(200,400]")
sample_data(ps)$family_relationship=gsub(" ","",sample_data(ps)$family_relationship)
pslog <- transform_sample_counts(ps, function(x) log(1 + x))
out.wuf.log <- ordinate(pslog, method = "MDS", distance = "wunifrac")
evals <- out.wuf.log$values$Eigenvalues
plot_ordination(pslog, out.wuf.log, color = "age_binned") +
  labs(col = "Binned Age") +
  coord_fixed(sqrt(evals[2] / evals[1]))
```
```{r}
  rel_abund <- t(apply(otu_table(ps), 1, function(x) x / sum(x)))
qplot(rel_abund[, 12], geom = "histogram",binwidth=0.05) +
  xlab("Relative abundance")
```
After documenting the outliers, we are going to compute ordinations with these outliers removed and more carefully study the output
```{r}
outliers <- c("F5D165", "F6D165", "M3D175", "M4D175", "M5D175", "M6D175")
ps <- prune_samples(!(sample_names(ps) %in% outliers), ps)
```

```{r}
which(!rowSums(otu_table(ps)) > 1000)
```

```{r}
ps <- prune_samples(rowSums(otu_table(ps)) > 1000, ps)
pslog <- transform_sample_counts(ps, function(x) log(1 + x))
```

We’ll first perform a PCoA using Bray-Curtis dissimilarity.
```{r}
out.pcoa.log <- ordinate(pslog,  method = "MDS", distance = "bray")
evals <- out.pcoa.log$values[,1]
plot_ordination(pslog, out.pcoa.log, color = "age_binned",
                  shape = "family_relationship") +
  labs(col = "Binned Age", shape = "Litter")+
  coord_fixed(sqrt(evals[2] / evals[1]))
```

Next we look at double principal coordinates analysis (DPCoA) (Pavoine, Dufour, and Chessel 2004; Purdom 2010; Fukuyama et al. 2012), which is a phylogenetic ordination method and that provides a biplot representation of both samples and taxonomic categories. We see again that the second axis corresponds to young vs. old mice
```{r}
out.dpcoa.log <- ordinate(pslog, method = "DPCoA")
evals <- out.dpcoa.log$eig
plot_ordination(pslog, out.dpcoa.log, color = "age_binned", label= "SampleID",
                  shape = "family_relationship") +
  labs(col = "Binned Age", shape = "Litter")+
  coord_fixed(sqrt(evals[2] / evals[1]))
```
```{r}
plot_ordination(pslog, out.dpcoa.log, type = "species", color = "Phylum") +
  coord_fixed(sqrt(evals[2] / evals[1]))
```

Finally, we can look at the results of PCoA with weighted Unifrac. As before, we find that the second axis is associated with an age effect, which is fairly similar to DPCoA. This is not surprising, because both are phylogenetic ordination methods taking abundance into account. However, when we compare biplots, we see that the DPCoA gave a much cleaner interpretation of the second axis, compared to weighted Unifrac.
```{r}
out.wuf.log <- ordinate(pslog, method = "PCoA", distance ="wunifrac")
evals <- out.wuf.log$values$Eigenvalues
plot_ordination(pslog, out.wuf.log, color = "age_binned",
                  shape = "family_relationship") +
  coord_fixed(sqrt(evals[2] / evals[1])) +
  labs(col = "Binned Age", shape = "Litter")
```

The PCoA maps are not presented as square representations as is often the case in standard PCoA and PCA plots in the literature.The reason for this is that as we are trying to represent the distances between samples as faithfully as possible; we have to take into account that the second eigenvalue is always smaller than the first, sometimes considerably so, thus we normalize the axis norm ratios to the relevant eigenvalue ratios. This ensures that the variability represented in the plots is done so faithfully.

```{r}
abund <- otu_table(pslog)
abund_ranks <- t(apply(abund, 1, rank))
```

```{r}
abund_ranks <- abund_ranks - 329
abund_ranks[abund_ranks < 1] <- 1
```

```{r}
library(dplyr)
library(reshape2)
abund_df <- melt(abund, value.name = "abund") %>%
  left_join(melt(abund_ranks, value.name = "rank"))
colnames(abund_df) <- c("sample", "seq", "abund", "rank")

abund_df <- melt(abund, value.name = "abund") %>%
  left_join(melt(abund_ranks, value.name = "rank"))
colnames(abund_df) <- c("sample", "seq", "abund", "rank")

sample_ix <- sample(1:nrow(abund_df), 8)
ggplot(abund_df %>%
         filter(sample %in% abund_df$sample[sample_ix])) +
  geom_point(aes(x = abund, y = rank, col = sample),
             position = position_jitter(width = 0.2), size = 1.5) +
  labs(x = "Abundance", y = "Thresholded rank") +
  scale_color_brewer(palette = "Set2")
```

```{r}
library(ade4)
ranks_pca <- dudi.pca(abund_ranks, scannf = F, nf = 3)
row_scores <- data.frame(li = ranks_pca$li,
                         SampleID = rownames(abund_ranks))
col_scores <- data.frame(co = ranks_pca$co,
                         seq = colnames(abund_ranks))
tax <- tax_table(ps) %>%
  data.frame(stringsAsFactors = FALSE)
tax$seq <- rownames(tax)
main_orders <- c("Clostridiales", "Bacteroidales", "Lactobacillales",
                 "Coriobacteriales")
tax$Order[!(tax$Order %in% main_orders)] <- "Other"
tax$Order <- factor(tax$Order, levels = c(main_orders, "Other"))
tax$otu_id <- seq_len(ncol(otu_table(ps)))
row_scores <- row_scores %>%
  left_join(sample_data(pslog))
col_scores <- col_scores %>%
  left_join(tax)
evals_prop <- 100 * (ranks_pca$eig / sum(ranks_pca$eig))
ggplot() +
  geom_point(data = row_scores, aes(x = li.Axis1, y = li.Axis2), shape = 2) +
  geom_point(data = col_scores, aes(x = 25 * co.Comp1, y = 25 * co.Comp2, col = Order),
             size = .3, alpha = 0.6) +
  scale_color_brewer(palette = "Set2") +
  facet_grid(~ age_binned) +
  guides(col = guide_legend(override.aes = list(size = 3))) +
  labs(x = sprintf("Axis1 [%s%% variance]", round(evals_prop[1], 2)),
       y = sprintf("Axis2 [%s%% variance]", round(evals_prop[2], 2))) +
  coord_fixed(sqrt(ranks_pca$eig[2] / ranks_pca$eig[1])) +
  theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)))
```
```{r}
ps_ccpna <- ordinate(pslog, "CCA", formula = pslog ~ age_binned + family_relationship)
library(ggrepel)
ps_scores <- vegan::scores(ps_ccpna)
sites <- data.frame(ps_scores$sites)
sites$SampleID <- rownames(sites)
sites <- sites %>%
  left_join(sample_data(ps))

species <- data.frame(ps_scores$species)
species$otu_id <- seq_along(colnames(otu_table(ps)))
species <- species %>%
  left_join(tax)
evals_prop <- 100 * ps_ccpna$CCA$eig[1:2] / sum(ps_ccpna$CA$eig)
ggplot() +
  geom_point(data = sites, aes(x = CCA1, y = CCA2), shape = 2, alpha = 0.5) +
  geom_point(data = species, aes(x = CCA1, y = CCA2, col = Order), size = 0.5) +
  geom_text_repel(data = species %>% filter(CCA2 < -2),
                    aes(x = CCA1, y = CCA2, label = otu_id),
            size = 1.5, segment.size = 0.1) +
  facet_grid(. ~ family_relationship) +
  guides(col = guide_legend(override.aes = list(size = 3))) +
  labs(x = sprintf("Axis1 [%s%% variance]", round(evals_prop[1], 2)),
        y = sprintf("Axis2 [%s%% variance]", round(evals_prop[2], 2))) +
  scale_color_brewer(palette = "Set2") +
  coord_fixed(sqrt(ps_ccpna$CCA$eig[2] / ps_ccpna$CCA$eig[1])*0.45   ) +
  theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)))
```

```{r}
library(caret)
library(lattice)
sample_data(pslog)$age2 <- cut(sample_data(pslog)$age, c(0, 100, 400))
dataMatrix <- data.frame(age = sample_data(pslog)$age2, otu_table(pslog))
# take 8 mice at random to be the training set, and the remaining 4 the test set
trainingMice <- sample(unique(sample_data(pslog)$host_subject_id), size = 8)
inTrain <- which(sample_data(pslog)$host_subject_id %in% trainingMice)
training <- dataMatrix[inTrain,]
testing <- dataMatrix[-inTrain,]
plsFit <- train(age ~ ., data = training,
                method = "pls", preProc = "center")
plsClasses <- predict(plsFit, newdata = testing)
table(plsClasses, testing$age)
```

```{r}
library(randomForest)
library(dplyr)
library(gridExtra)
library(ggplot2)
library(BiocGenerics)
rfFit <- train(age ~ ., data = training, method = "rf",
               preProc = "center", proximity = TRUE)
rfClasses <- predict(rfFit, newdata = testing)
table(rfClasses, testing$age)
```

```{r}
library(vegan)
pls_biplot <- list("loadings" = loadings(plsFit$finalModel),
                   "scores" = scores(plsFit$finalModel))
class(pls_biplot$scores) <- "matrix"

pls_biplot$scores <- data.frame(sample_data(pslog)[inTrain, ],
                                pls_biplot$scores)

tax <- tax_table(ps)@.Data %>%
  data.frame(stringsAsFactors = FALSE)
main_orders <- c("Clostridiales", "Bacteroidales", "Lactobacillales",
                 "Coriobacteriales")
tax$Order[!(tax$Order %in% main_orders)] <- "Other"
tax$Order <- factor(tax$Order, levels = c(main_orders, "Other"))
class(pls_biplot$loadings) <- "matrix"
pls_biplot$loadings <- data.frame(tax, pls_biplot$loadings)
ggplot() +
  geom_point(data = pls_biplot$scores,
             aes(x = Comp.1, y = Comp.2), shape = 2) +
  geom_point(data = pls_biplot$loadings,
             aes(x = 25 * Comp.1, y = 25 * Comp.2, col = Order),
             size = 0.3, alpha = 0.6) +
  scale_color_brewer(palette = "Set2") +
  labs(x = "Axis1", y = "Axis2", col = "Binned Age") +
  guides(col = guide_legend(override.aes = list(size = 3))) +
  facet_grid( ~ age2) +
  theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)))
```
```{r}
rf_prox <- cmdscale(1 - rfFit$finalModel$proximity) %>%
  data.frame(sample_data(pslog)[inTrain, ])

ggplot(rf_prox) +
  geom_point(aes(x = X1, y = X2, col = age_binned),
             size = 1, alpha = 0.7) +
  scale_color_manual(values = c("#A66EB8", "#238DB5", "#748B4F")) +
  guides(col = guide_legend(override.aes = list(size = 4))) +
  labs(col = "Binned Age", x = "Axis1", y = "Axis2")
``` 

```{r}
as.vector(tax_table(ps)[which.max(importance(rfFit$finalModel)), c("Family", "Genus")])

impOtu <- as.vector(otu_table(pslog)[,which.max(importance(rfFit$finalModel))])
maxImpDF <- data.frame(sample_data(pslog), abund = impOtu)
ggplot(maxImpDF) +   geom_histogram(aes(x = abund)) +
  facet_grid(age2 ~ .) +
  labs(x = "Abundance of discriminative bacteria", y = "Number of samples")
```

```{r}
library("phyloseqGraphTest")
library("igraph")
library("ggnetwork")
library(vegan)
library(permute)
library(dplyr)
library(phangorn)
library(ape)
library(Biostrings)
library(IRanges)
library(S4Vectors)
library(BiocGenerics)
library(stats)
library(base)
net <- make_network(ps, max.dist=0.35)
sampledata <- data.frame(sample_data(ps))
V(net)$id <- sampledata[names(V(net)), "host_subject_id"]
V(net)$litter <- sampledata[names(V(net)), "family_relationship"]

net_graph<-ggnetwork(net)

ggplot(net_graph, aes(x = x, y = y, xend = xend, yend = yend), layout = "fruchtermanreingold") +
  geom_edges(color = "darkgray") +
  geom_nodes(aes(color = id, shape = litter),  size = 3 ) +
  theme(axis.text = element_blank(), axis.title = element_blank(),
        legend.key.height = unit(0.5,"line")) +
  guides(col = guide_legend(override.aes = list(size = .5)))
```
#Graph-based two-sample tests
##Minimum Spanning Tree (MST)

Jaccard dissimilarity

```{r}
gt <- graph_perm_test(ps, "family_relationship", grouping = "host_subject_id",
                      distance = "jaccard", type = "mst")
gt$pval

plotNet1=plot_test_network(gt) + theme(legend.text = element_text(size = 8),
        legend.title = element_text(size = 9))
plotPerm1=plot_permutations(gt)
grid.arrange(ncol = 2,  plotNet1, plotPerm1)
```
##Nearest neighbors

```{r}
gt <- graph_perm_test(ps, "family_relationship", grouping = "host_subject_id",
                      distance = "jaccard", type = "knn", knn = 1)
plotNet2=plot_test_network(gt) + theme(legend.text = element_text(size = 8),
        legend.title = element_text(size = 9))
plotPerm2=plot_permutations(gt)
grid.arrange(ncol = 2,  plotNet2, plotPerm2)
```


#Linear modeling:
Unlike ordination, the purpose of this analysis is not to develop a representation of many bacteria with respect to sample characteristics; rather, it is to describe how a single measure of overall community structure[^1] is associated with sample characteristics.

##mixed-effects model to study the relationship between mouse microbial community diversity and the age and litter variables that have been our focus so far.

###We first compute the Shannon diversity associated with each sample and join it with sample annotation.
```{r}
library("nlme")
library("reshape2")
ps_alpha_div <- estimate_richness(ps, split = TRUE, measure = "Shannon")
ps_alpha_div$SampleID <- rownames(ps_alpha_div) %>%
  as.factor()
ps_samp <- sample_data(ps) %>%
  unclass() %>%
  data.frame() %>%
  left_join(ps_alpha_div, by = "SampleID") %>%
  melt(measure.vars = "Shannon",
       variable.name = "diversity_measure",
       value.name = "alpha_diversity")

# reorder's facet from lowest to highest diversity
diversity_means <- ps_samp %>%
  group_by(host_subject_id) %>%
  summarise(mean_div = mean(alpha_diversity)) %>%
  arrange(mean_div)
ps_samp$host_subject_id <- factor(ps_samp$host_subject_id)
#                                  diversity_means$host_subject_id)
alpha_div_model <- lme(fixed = alpha_diversity ~ age_binned, data = ps_samp,
                       random = ~ 1 | host_subject_id)
new_data <- expand.grid(host_subject_id = levels(ps_samp$host_subject_id),
                        age_binned = levels(ps_samp$age_binned))
new_data$pred <- predict(alpha_div_model, newdata = new_data)
X <- model.matrix(eval(eval(alpha_div_model$call$fixed)[-2]),
                  new_data[-ncol(new_data)])
pred_var_fixed <- diag(X %*% alpha_div_model$varFix %*% t(X))
new_data$pred_var <- pred_var_fixed + alpha_div_model$sigma ^ 2
# fitted values, with error bars
ggplot(ps_samp %>% left_join(new_data)) +
  geom_errorbar(aes(x = age_binned, ymin = pred - 2 * sqrt(pred_var),
                    ymax = pred + 2 * sqrt(pred_var)),
                col = "#858585", size = .1) +
  geom_point(aes(x = age_binned, y = alpha_diversity,
                 col = family_relationship), size = 0.8) +
  facet_wrap(~host_subject_id) +
  scale_y_continuous(limits = c(2.4, 4.6), breaks = seq(0, 5, .5)) +
  scale_color_brewer(palette = "Set2") +
  labs(x = "Binned Age", y = "Shannon Diversity", color = "Litter") +
  guides(col = guide_legend(override.aes = list(size = 4))) +
  theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)),
        axis.text.x = element_text(angle = -90, size = 6),
        axis.text.y = element_text(size = 6))
```


#Hierarchical multiple testing

```{r}
library("reshape2")
if(!requireNamespace("BiocManager",quietly=TRUE)) install.packages("BiocManager")
BiocManager::install("DESeq2")
library("DESeq2")
#New version of DESeq2 needs special levels
sample_data(ps)$age_binned <- cut(sample_data(ps)$age,
                          breaks = c(0, 100, 200, 400))
levels(sample_data(ps)$age_binned) <- list(Young100="(0,100]", Mid100to200="(100,200]", Old200="(200,400]")
sample_data(ps)$family_relationship = gsub(" ", "", sample_data(ps)$family_relationship)
ps_dds <- phyloseq_to_deseq2(ps, design = ~ age_binned + family_relationship)

# geometric mean, set to zero when all coordinates are zero
geo_mean_protected <- function(x) {
  if (all(x == 0)) {
    return (0)
  }
  exp(mean(log(x[x != 0])))
}

geoMeans <- apply(counts(ps_dds), 1, geo_mean_protected)
ps_dds <- estimateSizeFactors(ps_dds, geoMeans = geoMeans)
ps_dds <- estimateDispersions(ps_dds)
abund <- getVarianceStabilizedData(ps_dds)

short_names <- substr(rownames(abund), 1, 5)%>%
  make.names(unique = TRUE)
rownames(abund) <- short_names

abund_sums <- rbind(data.frame(sum = colSums(abund),
                               sample = colnames(abund),
                               type = "DESeq2"),
                    data.frame(sum = rowSums(otu_table(pslog)),
                               sample = rownames(otu_table(pslog)),
                               type = "log(1 + x)"))

ggplot(abund_sums) +
  geom_histogram(aes(x = sum), binwidth = 20) +
  facet_grid(type ~ .) +
  xlab("Total abundance within sample")
```
```{r}
library("structSSI")
el <- phy_tree(pslog)$edge
el0 <- el
el0 <- el0[nrow(el):1, ]
el_names <- c(short_names, seq_len(phy_tree(pslog)$Nnode))
el[, 1] <- el_names[el0[, 1]]
el[, 2] <- el_names[as.numeric(el0[, 2])]
unadj_p <- treePValues(el, abund, sample_data(pslog)$age_binned)

hfdr_res <- hFDR.adjust(unadj_p, el, .75)
summary(hfdr_res)
```

```{r}
plot(hfdr_res, height = 5000) #opens in a browser
```

```{r}
tax <- tax_table(pslog)[, c("Family", "Genus")] %>%
  data.frame()
tax$seq <- short_names
options(digits=3)
hfdr_res@p.vals$seq <- rownames(hfdr_res@p.vals)
tax %>%
  left_join(hfdr_res@p.vals) %>%
  arrange(adjp) %>% head(10)
```
#Multitable techniques

```{r}
metab <- read.csv("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/metabolites.csv",row.names = 1)
microbe_connect <-url("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/microbe.rda")
load(microbe_connect)
microbe
```
```{r}
library("genefilter")
library(matrixStats)
keep_ix <- rowSums(metab == 0) <= 3
metab <- metab[keep_ix, ]
microbe <- prune_taxa(taxa_sums(microbe) > 4, microbe)
microbe <- filter_taxa(microbe, filterfun(kOverA(3, 2)), TRUE)
metab <- log(1 + metab, base = 10)
X <- otu_table(microbe)
X[X > 50] <- 50
dim(X)
#ligne deux de tableau:
dim(metab)
```

```{r}
library(PMA)
cca_res <- CCA(t(X),  t(metab), penaltyx = .15, penaltyz = .15)
```

```{r}
cca_res
```

```{r}
combined <- cbind(t(X[cca_res$u != 0, ]),
                  t(metab[cca_res$v != 0, ]))
pca_res <- dudi.pca(combined, scannf = F, nf = 3)
genotype <- substr(rownames(pca_res$li), 1, 2)
sample_type <- substr(rownames(pca_res$l1), 3, 4)
feature_type <- grepl("\\.", colnames(combined))
feature_type <- ifelse(feature_type, "Metabolite", "OTU")
sample_info <- data.frame(pca_res$li, genotype, sample_type)
feature_info <- data.frame(pca_res$c1,
                           feature = substr(colnames(combined), 1, 6))
ggplot() +  geom_point(data = sample_info,
            aes(x = Axis1, y = Axis2, col = sample_type, shape = genotype), size = 3) + 
  geom_label_repel(data = feature_info,
                   aes(x = 5.5 * CS1, y = 5.5 * CS2, label = feature, fill = feature_type),
                   size = 2, segment.size = 0.3,
                   label.padding = unit(0.1, "lines"), label.size = 0) +
  geom_point(data = feature_info,
             aes(x = 5.5 * CS1, y = 5.5 * CS2, fill = feature_type),
             size = 1, shape = 23, col = "#383838") +
  scale_color_brewer(palette = "Set2") +
  scale_fill_manual(values = c("#a6d854", "#e78ac3")) +
  guides(fill = guide_legend(override.aes = list(shape = 32, size = 0))) +
  coord_fixed(sqrt(pca_res$eig[2] / pca_res$eig[2])) +
  labs(x = sprintf("Axis1 [%s%% Variance]",
                   100 * round(pca_res$eig[1] / sum(pca_res$eig), 2)),
       y = sprintf("Axis2 [%s%% Variance]",
                   100 * round(pca_res$eig[2] / sum(pca_res$eig), 2)),
       fill = "Feature Type", col = "Sample Type")
```

